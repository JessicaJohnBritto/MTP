{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34d2381-a1b7-47a9-96b6-3c9416039674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pyblock2.driver.core import DMRGDriver, SymmetryTypes, MPOAlgorithmTypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf94e558-a30e-4132-baa3-80c46b657a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_file_path():\n",
    "    current_file = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    return current_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b929e0-9d81-489b-9805-9936b3b719c0",
   "metadata": {},
   "source": [
    "# Data Storing Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99581899-3575-4b9f-94b5-2d6c74f624fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variable_name(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a variable name dynamically based on the given parameters.\n",
    "    Parameters:\n",
    "    - params (dict): A dictionary containing 't' and 'theta_foldername' as keys.\n",
    "    Returns:\n",
    "    - str: The dynamically generated variable name.\n",
    "    \"\"\"\n",
    "    t_value = params['t']\n",
    "    u_value = params['u']\n",
    "    if t_value != 0:\n",
    "        t_formatted = \"{:.1e}\".format(t_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        t_formatted = \"0e0\"\n",
    "\n",
    "    if u_value != 0:\n",
    "        U_formatted = \"{:.1e}\".format(u_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        U_formatted = \"0e0\"\n",
    "    theta_formatted = params['theta_foldername']\n",
    "    return f\"data_t{t_formatted}_U{U_formatted}_theta{theta_formatted}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c83ba-0de0-4eca-b747-419f7c43e6b4",
   "metadata": {},
   "source": [
    "## HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65435354-ab8a-44b4-8d94-6e6950bd7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_key(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a unique key for the HDF5 dataset based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - params (dict): Dictionary containing 't' and 'u' values.\n",
    "    - kwargs (dict): Dictionary of additional key-value pairs for key generation.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted unique key.\n",
    "    \"\"\"\n",
    "    t_value = params['t']\n",
    "    u_value = params['u']\n",
    "\n",
    "    if t_value != 0:\n",
    "        t_formatted = \"{:.1e}\".format(t_value).replace(\"+\", \"\").replace(\".\", \"_\").replace(\"e0\", \"e\").replace(\"-\", \"\")\n",
    "    else:\n",
    "        t_formatted = \"0e0\"\n",
    "\n",
    "    if u_value != 0:\n",
    "        U_formatted = \"{:.1e}\".format(u_value).replace(\"+\", \"\").replace(\".\", \"_\").replace(\"e0\", \"e\").replace(\"-\", \"\")\n",
    "    else:\n",
    "        U_formatted = \"0e0\"\n",
    "\n",
    "    if 'std_deviation_numberOp' in kwargs:\n",
    "        key = f\"std_deviation_numberOp_U{U_formatted}_t{t_formatted}\"\n",
    "    elif 'exp_nOp' in kwargs:\n",
    "        key = f\"expnOp_U{U_formatted}_t{t_formatted}\"\n",
    "    elif 'gndstate_energy' in kwargs:\n",
    "        key = f\"gndenergy_U{U_formatted}_t{t_formatted}\"\n",
    "    elif 'firstexcitedenergy' in kwargs:\n",
    "        key = f\"firstexcitedenergy_U{U_formatted}_t{t_formatted}\"\n",
    "    return key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff014658-8729-41b4-aaaf-edbc5c03a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_complete_path_hdf5(filename, **kwargs):\n",
    "    current_file = current_file_path()\n",
    "    if params['theta_foldername'] == '0':\n",
    "        if 'Correlation' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta{params['theta_foldername']}', f'L{params['L']}','Correl_matrix',filename)\n",
    "        elif 'entropy' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta{params['theta_foldername']}', f'L{params['L']}','Entropy',filename)\n",
    "        elif 'expnop' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta{params['theta_foldername']}', f'L{params['L']}','Exp_nOp',filename)\n",
    "        else:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta{params['theta_foldername']}', f'L{params['L']}','Remainig_Data',filename)\n",
    "    else:\n",
    "        if 'Correlation' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta_{params['theta_foldername']}', f'L{params['L']}','Correl_matrix',filename)\n",
    "        elif 'entropy' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta_{params['theta_foldername']}', f'L{params['L']}','Entropy',filename)\n",
    "        elif 'expnop' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta_{params['theta_foldername']}', f'L{params['L']}','Exp_nOp',filename)\n",
    "        else:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f'theta_{params['theta_foldername']}', f'L{params['L']}','Remainig_Data',filename)\n",
    "    return complete_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceef8db5-acaf-4ede-9f7a-d9cda91e508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_and_store_data(params, data, filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Create folders dynamically based on theta and L values, and store data in a file.\n",
    "    Writes data - overwrite if file already exists\n",
    "    Parameters:\n",
    "    - theta (float or str): The value of theta (e.g., 0, pi/4, pi/2, etc.).\n",
    "    - L (int): The integer value of L.\n",
    "    - data (DataFrame): The data to be stored.\n",
    "    - filename (str): The name of the file to store data in.\n",
    "    \"\"\"\n",
    "    # Define the base directory\n",
    "    if params['theta_foldername'] == '0':\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:      \n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    else:\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    # Create directories if they don't exist\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Define the full file path\n",
    "    file_path = base_dir / filename\n",
    "    # Writing the data to a HDF5 file in the created directory\n",
    "    data.to_hdf(file_path, key=kwargs['key'], mode='w')\n",
    "\n",
    "# filename = 'testing.csv'\n",
    "# data=  pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "# key = 'testing'\n",
    "# params['L'] = 10\n",
    "# params['theta_foldername'] = '0'\n",
    "# create_folders_and_store_data(params, data, filename, key = key, Entropy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76cc9b95-d822-4459-aca6-deac9a45c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_hdf5(params, data, file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    This is useful only when the folder exists and you want to create new hdf5 file.\n",
    "    Write a single dataset to an HDF5 file under a specified key.\n",
    "    Parameters:\n",
    "    - file_name (str): The name of the HDF5 file.\n",
    "    - data (pd.DataFrame or pd.Series): The data to write to the HDF5 file.\n",
    "    - key (str): The key under which the data will be stored in the HDF5 file.\n",
    "    \"\"\"\n",
    "    data.to_hdf(file_name, key=kwargs['key'], mode='a', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58468629-3147-4f10-bc15-10f32be91b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_name_hdf5(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a file name dynamically based on the given parameters.\n",
    "    Parameters:\n",
    "    - params (dict): A dictionary containing 'L', 'nmax', and 't' as keys.\n",
    "    Returns:\n",
    "    - str: The dynamically generated file name.\n",
    "    \"\"\"\n",
    "    # Format the 't' value to scientific notation if needed\n",
    "    t_value = params['t']\n",
    "    u_value = params['u']\n",
    "    \n",
    "    if t_value != 0:\n",
    "        t_formatted = \"{:.1e}\".format(t_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        t_formatted = \"0e0\"\n",
    "\n",
    "    if u_value != 0:\n",
    "        U_formatted = \"{:.1e}\".format(u_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        U_formatted = \"0e0\"\n",
    "\n",
    "    if 'Correlation' in kwargs:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}_CorrelationMatrix.h5\"\n",
    "    elif 'entropy' in kwargs:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}_entropy.h5\"\n",
    "    elif 'expnop' in kwargs:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}_expnop.h5\"\n",
    "    else:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}.h5\"\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9f47fc-acc4-46b7-8bf8-7cc4c46558ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matrix_from_hdf5(filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Load a matrix from an HDF5 file using pandas.\n",
    "    Parameters:\n",
    "    - filepath (str or Path): The path to the HDF5 file.\n",
    "    - key (str): The key to the dataset to load (default is 'correlation_matrix').\n",
    "    Returns:\n",
    "    - ndarray: The matrix loaded from the HDF5 file as a NumPy array.\n",
    "    \"\"\"\n",
    "    df = pd.read_hdf(filepath, key=kwargs['key'])\n",
    "    return df.values  # Convert the DataFrame to a NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f98d899-a69e-4a68-9ff5-1286ed47e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data_to_hdf5(params, data, filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Create folders dynamically based on theta and L values, and append data to an HDF5 file.\n",
    "    \n",
    "    If the file does not exist, it will be created. If it does exist, the data will be appended.\n",
    "\n",
    "    Parameters:\n",
    "    - theta (float or str): The value of theta (e.g., 0, pi/4, pi/2, etc.).\n",
    "    - L (int): The integer value of L.\n",
    "    - data (DataFrame or Series): The data to append.\n",
    "    - filename (str): The name of the HDF5 file to store/append data.\n",
    "    - key (str): The key under which the data is stored in the HDF5 file.\n",
    "    \"\"\"\n",
    "    # Define the base directory\n",
    "    if params['theta_foldername'] == '0':\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:      \n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    else:\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define the full file path\n",
    "    file_path = base_dir / filename\n",
    "    \n",
    "    # Append the data to the HDF5 file (create the file if it doesn't exist)\n",
    "    data.to_hdf(file_path, key=kwargs['key'], mode='a', index=False, append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c80589-43d7-47c2-bf93-3b44a8b41d49",
   "metadata": {},
   "source": [
    "# Data for a $\\theta$, $L$, $N\\_{Boson}$, $N\\_{Max}$, $U$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ddfdc9-0ba0-4c7a-a2ef-936f5ae00057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params={}\n",
    "params['L'], params['N_BOSON'] = 20, 20\n",
    "params['theta_foldername_list'] = ['0', 'Piby4', 'Piby2', '3Piby4', 'Pi']\n",
    "params['theta'], params['theta_foldername'] = np.pi, params['theta_foldername_list'][4]\n",
    "params['t'] = 1\n",
    "params['u'] = 1\n",
    "params['mu'] = 0\n",
    "params['NB_MAX'] = 3 # max n_boson per site\n",
    "params['theta_list'] = [0, np.pi/4, 3*np.pi/4, np.pi/2, np.pi]\n",
    "params['t_list'] = np.arange(0.01, 2, 0.1)\n",
    "\n",
    "driver = DMRGDriver(scratch=\"./tmp\", symm_type=SymmetryTypes.SAny|SymmetryTypes.CPX, n_threads=4)\n",
    "\n",
    "driver.set_symmetry_groups(\"U1\")\n",
    "Q = driver.bw.SX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d440c38a-272f-4fa6-823f-c14a77b7e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_basis, site_ops = [], []\n",
    "for k in range(params['L']):\n",
    "    basis = [(Q(i), 1) for i in range(params['NB_MAX'] + 1)] \n",
    "    ops = {\n",
    "        \"\": np.identity(params['NB_MAX'] + 1),                           # identity\n",
    "        \"C\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1)), k=-1), # b+\n",
    "        \"D\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1)), k=1),  # b\n",
    "        \"N\": np.diag(np.arange(0, params['NB_MAX'] + 1), k=0),           # particle number\n",
    "        \"A\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1))*np.exp(1j * params['theta'] * np.arange(params['NB_MAX'])), k=-1), # A+_withPhase  \n",
    "        \"B\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1))*np.exp(-1j * params['theta'] * np.arange(params['NB_MAX'])), k=1), # A_withPhase  \n",
    "    }\n",
    "    site_basis.append(basis)\n",
    "    site_ops.append(ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60024b09-ef05-4c8d-a818-a606d1dcb292",
   "metadata": {},
   "source": [
    "## First Excited Gap, Correlation, Number Operator and Entropy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5e942-8643-4cb1-a358-3fb2e9ff8856",
   "metadata": {},
   "source": [
    "#### $U$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "648a6640-041e-406c-9da2-691d5aab9003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 862.17 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "## Change the value of U\n",
    "params['u'] = 0.4\n",
    "\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e3a84968-99cc-42b5-bcd6-5dcd4a8f1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1e3e5-1ee9-4610-b5f0-c20e271bd421",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e0468cbd-b91b-41ce-8adc-94402b1f39c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gndenergy_U0e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "77ccdc25-6b5c-4f70-ab42-698ab420946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023817859262807574\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f8177-151d-4110-ab0d-2266d8140d74",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b244a34-e432-473b-9c06-66c87b81ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139825a0-ba03-4cbc-b69b-e708c6c7d4ac",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c81f4cf-265b-4f23-a0c5-3a63d095eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbb0ca-3fc2-4fb7-a645-893d9f14e4c4",
   "metadata": {},
   "source": [
    "###### CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b02f6ffe-fe6a-4344-b2a7-ec9284160c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using csv files\n",
    "update_csv_column(\"theta0_AHMDmrg_data.csv\", 'Entropy', 't', params['t'], str(entropy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8cab7-6d67-4a27-8220-179ade3bd06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data Storing using CSV files\n",
    "data_t0_theta0 = [[params['L'], params['t'], params['u'], params['N_BOSON'], params['NB_MAX'], energy[0], mps, energy[1], entropy]]\n",
    "add_data_to_csv(\"theta0_AHMDmrg_data.csv\", data_t0_theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea9307-a4f1-4647-adfa-034471ae83eb",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bac5b627-2ded-4810-98f5-cbc8db7ba4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d3c0aa92-d634-4709-90bc-839ef74b250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "# append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ae342-c788-4f99-a9a4-7c9678cf104b",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8534bc00-ab84-4f9b-b08d-fceba8019ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a252b8-370f-4969-98a2-147ef5ee7242",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1b8e914b-21ed-4730-b292-776b25d1afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "create_folders_and_store_data(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc396c50-850b-49ba-a409-a5f597b21d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32979578-1.60189256e-17j]\n",
      " [1.20528299-3.03216448e-18j]\n",
      " [1.25048189-8.15554100e-17j]\n",
      " [1.05428918-9.97814628e-17j]\n",
      " [1.1601114 -2.85936539e-17j]\n",
      " [1.16011052-8.38035693e-19j]\n",
      " [1.05432905+4.59333730e-17j]\n",
      " [1.2504942 -6.07393261e-17j]\n",
      " [1.20529757-5.85440238e-17j]\n",
      " [0.3298074 -5.07139597e-17j]]\n"
     ]
    }
   ],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c877ab-6c01-47e0-beb4-8359d745f489",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "61c3fb5c-d554-4e22-bc6b-1482fcc731c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dd03dc0-a733-4105-85fa-09d233532b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8521473703424012+1.2753672184242906e-17j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b2196-82ea-4877-9dc7-3dfd4e761205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
