{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34d2381-a1b7-47a9-96b6-3c9416039674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pyblock2.driver.core import DMRGDriver, SymmetryTypes, MPOAlgorithmTypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf94e558-a30e-4132-baa3-80c46b657a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_file_path():\n",
    "    current_file = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "    return current_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b929e0-9d81-489b-9805-9936b3b719c0",
   "metadata": {},
   "source": [
    "# Data Storing Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99581899-3575-4b9f-94b5-2d6c74f624fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variable_name(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a variable name dynamically based on the given parameters.\n",
    "    Parameters:\n",
    "    - params (dict): A dictionary containing 't' and 'theta_foldername' as keys.\n",
    "    Returns:\n",
    "    - str: The dynamically generated variable name.\n",
    "    \"\"\"\n",
    "    t_value = params['t']\n",
    "    u_value = params['u']\n",
    "    if t_value != 0:\n",
    "        t_formatted = \"{:.1e}\".format(t_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        t_formatted = \"0e0\"\n",
    "\n",
    "    if u_value != 0:\n",
    "        U_formatted = \"{:.1e}\".format(u_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        U_formatted = \"0e0\"\n",
    "    theta_formatted = params['theta_foldername']\n",
    "    return f\"data_t{t_formatted}_U{U_formatted}_theta{theta_formatted}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c83ba-0de0-4eca-b747-419f7c43e6b4",
   "metadata": {},
   "source": [
    "## HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65435354-ab8a-44b4-8d94-6e6950bd7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_key(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a unique key for the HDF5 dataset based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - params (dict): Dictionary containing 't' and 'u' values.\n",
    "    - kwargs (dict): Dictionary of additional key-value pairs for key generation.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted unique key.\n",
    "    \"\"\"\n",
    "    t_value = params['t']\n",
    "    u_value = params['u']\n",
    "\n",
    "    if t_value != 0:\n",
    "        t_formatted = \"{:.1e}\".format(t_value).replace(\"+\", \"\").replace(\".\", \"_\").replace(\"e0\", \"e\").replace(\"-\", \"\")\n",
    "    else:\n",
    "        t_formatted = \"0e0\"\n",
    "\n",
    "    if u_value != 0:\n",
    "        U_formatted = \"{:.1e}\".format(u_value).replace(\"+\", \"\").replace(\".\", \"_\").replace(\"e0\", \"e\").replace(\"-\", \"\")\n",
    "    else:\n",
    "        U_formatted = \"0e0\"\n",
    "\n",
    "    if 'std_deviation_numberOp' in kwargs:\n",
    "        key = f\"std_deviation_numberOp_U{U_formatted}_t{t_formatted}\"\n",
    "    elif 'exp_nOp' in kwargs:\n",
    "        key = f\"expnOp_U{U_formatted}_t{t_formatted}\"\n",
    "    elif 'gndstate_energy' in kwargs:\n",
    "        key = f\"gndenergy_U{U_formatted}_t{t_formatted}\"\n",
    "    elif 'firstexcitedenergy' in kwargs:\n",
    "        key = f\"firstexcitedenergy_U{U_formatted}_t{t_formatted}\"\n",
    "    return key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff014658-8729-41b4-aaaf-edbc5c03a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_complete_path_hdf5(filename, **kwargs):\n",
    "    current_file = current_file_path()\n",
    "    if params['theta_foldername'] == '0':\n",
    "        if 'Correlation' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta{params['theta_foldername']}\", f\"L{params['L']}\",'Correl_matrix',filename)\n",
    "        elif 'entropy' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta{params['theta_foldername']}\", f\"L{params['L']}\",'Entropy',filename)\n",
    "        elif 'expnop' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta{params['theta_foldername']}\", f\"L{params['L']}\",'Exp_nOp',filename)\n",
    "        else:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta{params['theta_foldername']}\", f\"L{params['L']}\",'Remainig_Data',filename)\n",
    "    else:\n",
    "        if 'Correlation' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta_{params['theta_foldername']}\", f\"L{params['L']}\",'Correl_matrix',filename)\n",
    "        elif 'entropy' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta_{params['theta_foldername']}\", f\"L{params['L']}\",'Entropy',filename)\n",
    "        elif 'expnop' in kwargs:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta_{params['theta_foldername']}\", f\"L{params['L']}\",'Exp_nOp',filename)\n",
    "        else:\n",
    "            complete_path = os.path.join(current_file, 'AHM_Data_Codes', f\"theta_{params['theta_foldername']}\", f\"L{params['L']}\",'Remainig_Data',filename)\n",
    "    return complete_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceef8db5-acaf-4ede-9f7a-d9cda91e508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_and_store_data(params, data, filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Create folders dynamically based on theta and L values, and store data in a file.\n",
    "    Writes data - overwrite if file already exists\n",
    "    Parameters:\n",
    "    - theta (float or str): The value of theta (e.g., 0, pi/4, pi/2, etc.).\n",
    "    - L (int): The integer value of L.\n",
    "    - data (DataFrame): The data to be stored.\n",
    "    - filename (str): The name of the file to store data in.\n",
    "    \"\"\"\n",
    "    # Define the base directory\n",
    "    if params['theta_foldername'] == '0':\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:      \n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    else:\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    # Create directories if they don't exist\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Define the full file path\n",
    "    file_path = base_dir / filename\n",
    "    # Writing the data to a HDF5 file in the created directory\n",
    "    data.to_hdf(file_path, key=kwargs['key'], mode='w')\n",
    "\n",
    "# filename = 'testing.csv'\n",
    "# data=  pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "# key = 'testing'\n",
    "# params['L'] = 10\n",
    "# params['theta_foldername'] = '0'\n",
    "# create_folders_and_store_data(params, data, filename, key = key, Entropy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76cc9b95-d822-4459-aca6-deac9a45c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_hdf5(params, data, file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    This is useful only when the folder exists and you want to create new hdf5 file.\n",
    "    Write a single dataset to an HDF5 file under a specified key.\n",
    "    Parameters:\n",
    "    - file_name (str): The name of the HDF5 file.\n",
    "    - data (pd.DataFrame or pd.Series): The data to write to the HDF5 file.\n",
    "    - key (str): The key under which the data will be stored in the HDF5 file.\n",
    "    \"\"\"\n",
    "    data.to_hdf(file_name, key=kwargs['key'], mode='a', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58468629-3147-4f10-bc15-10f32be91b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_name_hdf5(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a file name dynamically based on the given parameters.\n",
    "    Parameters:\n",
    "    - params (dict): A dictionary containing 'L', 'nmax', and 't' as keys.\n",
    "    Returns:\n",
    "    - str: The dynamically generated file name.\n",
    "    \"\"\"\n",
    "    # Format the 't' value to scientific notation if needed\n",
    "    t_value = params['t']\n",
    "    u_value = params['u']\n",
    "    \n",
    "    if t_value != 0:\n",
    "        t_formatted = \"{:.1e}\".format(t_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        t_formatted = \"0e0\"\n",
    "\n",
    "    if u_value != 0:\n",
    "        U_formatted = \"{:.1e}\".format(u_value).replace(\"+\", \"\").replace(\"e0\", \"e\")\n",
    "    else:\n",
    "        U_formatted = \"0e0\"\n",
    "\n",
    "    if 'Correlation' in kwargs:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}_CorrelationMatrix.h5\"\n",
    "    elif 'entropy' in kwargs:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}_entropy.h5\"\n",
    "    elif 'expnop' in kwargs:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}_expnop.h5\"\n",
    "    else:\n",
    "        file_name = f\"L{params['L']}_t{t_formatted}_Nmax{params['NB_MAX']}_Nbosons{params['N_BOSON']}_U{U_formatted}.h5\"\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9f47fc-acc4-46b7-8bf8-7cc4c46558ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matrix_from_hdf5(filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Load a matrix from an HDF5 file using pandas.\n",
    "    Parameters:\n",
    "    - filepath (str or Path): The path to the HDF5 file.\n",
    "    - key (str): The key to the dataset to load (default is 'correlation_matrix').\n",
    "    Returns:\n",
    "    - ndarray: The matrix loaded from the HDF5 file as a NumPy array.\n",
    "    \"\"\"\n",
    "    df = pd.read_hdf(filepath, key=kwargs['key'])\n",
    "    return df.values  # Convert the DataFrame to a NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f98d899-a69e-4a68-9ff5-1286ed47e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data_to_hdf5(params, data, filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Create folders dynamically based on theta and L values, and append data to an HDF5 file.\n",
    "    \n",
    "    If the file does not exist, it will be created. If it does exist, the data will be appended.\n",
    "\n",
    "    Parameters:\n",
    "    - theta (float or str): The value of theta (e.g., 0, pi/4, pi/2, etc.).\n",
    "    - L (int): The integer value of L.\n",
    "    - data (DataFrame or Series): The data to append.\n",
    "    - filename (str): The name of the HDF5 file to store/append data.\n",
    "    - key (str): The key under which the data is stored in the HDF5 file.\n",
    "    \"\"\"\n",
    "    # Define the base directory\n",
    "    if params['theta_foldername'] == '0':\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:      \n",
    "            base_dir = Path.cwd() / f\"theta{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    else:\n",
    "        if 'Correlation' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Correl_matrix'\n",
    "        elif 'entropy' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Entropy'\n",
    "        elif 'expnop' in kwargs:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Exp_nOp'\n",
    "        else:\n",
    "            base_dir = Path.cwd() / f\"theta_{params['theta_foldername']}\" / f\"L{params['L']}\" / 'Remainig_Data'\n",
    "    \n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = base_dir / filename\n",
    "    # Append the data to the HDF5 file (create the file if it doesn't exist)\n",
    "    data.to_hdf(file_path, key=kwargs['key'], mode='a', index=False, append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c80589-43d7-47c2-bf93-3b44a8b41d49",
   "metadata": {},
   "source": [
    "# Data for a $\\theta$, $L$, $N\\_{Boson}$, $N\\_{Max}$, $U$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8ddfdc9-0ba0-4c7a-a2ef-936f5ae00057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params={}\n",
    "params['L'], params['N_BOSON'] = 20, 20\n",
    "params['theta_foldername_list'] = ['0', 'Piby4', 'Piby2', '3Piby4', 'Pi']\n",
    "params['theta'], params['theta_foldername'] = np.pi, params['theta_foldername_list'][4]\n",
    "params['t'] = 1\n",
    "params['u'] = 1\n",
    "params['mu'] = 0\n",
    "params['NB_MAX'] = 3 # max n_boson per site\n",
    "params['theta_list'] = [0, np.pi/4, 3*np.pi/4, np.pi/2, np.pi]\n",
    "params['t_list'] = np.arange(0.01, 2, 0.1)\n",
    "\n",
    "driver = DMRGDriver(scratch=\"./tmp\", symm_type=SymmetryTypes.SAny|SymmetryTypes.CPX, n_threads=4)\n",
    "\n",
    "driver.set_symmetry_groups(\"U1\")\n",
    "Q = driver.bw.SX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d440c38a-272f-4fa6-823f-c14a77b7e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_basis, site_ops = [], []\n",
    "for k in range(params['L']):\n",
    "    basis = [(Q(i), 1) for i in range(params['NB_MAX'] + 1)] \n",
    "    ops = {\n",
    "        \"\": np.identity(params['NB_MAX'] + 1),                           # identity\n",
    "        \"C\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1)), k=-1), # b+\n",
    "        \"D\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1)), k=1),  # b\n",
    "        \"N\": np.diag(np.arange(0, params['NB_MAX'] + 1), k=0),           # particle number\n",
    "        \"A\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1))*np.exp(1j * params['theta'] * np.arange(params['NB_MAX'])), k=-1), # A+_withPhase  \n",
    "        \"B\": np.diag(np.sqrt(np.arange(1, params['NB_MAX'] + 1))*np.exp(-1j * params['theta'] * np.arange(params['NB_MAX'])), k=1), # A_withPhase  \n",
    "    }\n",
    "    site_basis.append(basis)\n",
    "    site_ops.append(ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60024b09-ef05-4c8d-a818-a606d1dcb292",
   "metadata": {},
   "source": [
    "## First Excited Gap, Correlation, Number Operator and Entropy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5e942-8643-4cb1-a358-3fb2e9ff8856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "648a6640-041e-406c-9da2-691d5aab9003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 862.17 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e3a84968-99cc-42b5-bcd6-5dcd4a8f1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c637f19-40c9-4ba0-b238-6170ad8ae4e5",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33a6a6-6bac-4674-b58a-3cfbdd0e8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2e00f-857c-443b-a694-647b2fffb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac792a21-27b8-45e0-abb9-31fc11bea29c",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a39a34-82de-4849-ad40-3aea6222cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80464d04-1bcf-4a88-8f00-2092f8b5dba5",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b56efc-4e4e-404c-9c88-cdd7ad7c4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b37590-6058-4e0d-8bc0-0e0d00804d84",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc4190-cd87-4cb7-a244-ee4d9f6777d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ab3d5-b19b-4095-81fe-2f07631527ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751ad41-b149-4c66-8120-629fe1ad0695",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0ecd5-fd2e-419a-b9ba-cd25c57c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5c4c7-65e3-4f2d-86a3-fec677aa4d65",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5cdf3-62dd-4883-9407-ff7bafb6bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2f440-2765-4244-b942-016a945907ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad71df-ac81-4cb8-a775-a507483392c1",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02995b-0520-4ce3-8cf6-c0381589afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52261d-22b7-48e0-832f-8f2d296ad47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54a01e-fb87-4275-bbb1-faed51e2a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389751e-4280-410b-a515-b4aa1b66c37e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Testing of Correlation Matrix by plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c048b5b-9ff9-4958-b74f-fb3f1b552627",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_values = [0]\n",
    "L_values = [10]\n",
    "\n",
    "example_data = pd.DataFrame({\n",
    "    'Column1': np.random.rand(10),\n",
    "    'Column2': np.random.rand(10)\n",
    "})\n",
    "\n",
    "for theta in theta_values:\n",
    "    for L in L_values:\n",
    "        filename = generate_file_name_hdf5(params)\n",
    "        create_folders_and_store_data(params, example_data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ecfaf7a-0127-4571-ba60-50c3a772e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = generate_file_name_hdf5(params, Correlation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "758f2f7c-a959-4a24-9c39-79e645acbe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "filename1 = os.path.join(current_file, 'AHM_Data_Codes', 'theta0', f'L{10}', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90d42fd3-f63a-4c05-b97e-2a78f983df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val1 = load_matrix_from_hdf5(filename1, key = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e074cb1-4bbc-4fa0-ab74-e97862a9f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val1 = np.power(np.abs(hop_exp_val1), 2)\n",
    "plt.imshow(hop_exp_val1, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f653c5a-a6bf-4dba-a40c-666091f9defc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Some Minor Testing of Scaling Laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0675d9a-17c3-4c38-82e3-00a810f24ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8666d4c0-6b15-49bf-bffd-6ddd967b653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0865267f-0989-480d-8101-aceb14489eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['t'] = 0\n",
    "update_csv_column(\"theta0_AHMDmrg_data.csv\", 'Entropy', 't', params['t'], str(entropy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cad76b7-7007-4ca8-aebc-11b45a215d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<block2.cpx.sany.MPS object at 0x0000015B1B3DE0B0>\n",
      "[-8.88178420e-16 -8.88178420e-16 -8.88178420e-16 -8.88178420e-16\n",
      " -8.88178420e-16 -8.88139235e-16  2.63409891e-10  1.22678750e-10\n",
      "  8.13411184e-11]\n"
     ]
    }
   ],
   "source": [
    "print(kets[0])\n",
    "print(entropy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51ff46c6-2cc1-45ab-974d-67873c93e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+000 3.41084312e-162 1.30021674e-078 9.50087542e-047\n",
      " 1.20819030e-014 9.63085519e-012 3.28992598e-002 7.32875617e-001\n",
      " 8.51719905e-001]\n"
     ]
    }
   ],
   "source": [
    "entropy2 = driver.get_bipartite_entanglement(kets[1])\n",
    "print(entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3429b49d-8936-4199-976e-0da566a9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"theta0_AHMDmrg_data.csv\")\n",
    "params['t'] = 0\n",
    "condition = df['t'] == params['t']\n",
    "df.loc[condition, 'Entropy'] = str(entropy1) * condition.sum()\n",
    "\n",
    "# Step 4: Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(\"theta0_AHMDmrg_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af0dc37-296a-41c8-be5a-3a968770117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d346695-f3e3-40c1-8afb-9ccf73016a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.8817842e-16, -8.8817842e-16, -8.8817842e-16, -8.8817842e-16, -8.8817842e-16, -8.88139235e-16, 2.63409891e-10, 1.2267875e-10, 8.13411184e-11]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_stringlist_to_float_list(string):\n",
    "    # Remove the square brackets and split by spaces\n",
    "    float_list = list(map(float, string.strip('[]').split()))\n",
    "    return float_list\n",
    "\n",
    "def get_data_by_conditions(df, conditions, columns):\n",
    "    condition = pd.Series([True] * len(df)) \n",
    "    for key, value in conditions.items():\n",
    "        condition &= df[key] == value\n",
    "    filtered_df = df[condition]\n",
    "    return filtered_df[columns] if not filtered_df.empty else None\n",
    "colors1 = plt.cm.Reds(np.linspace(0.5, 0.95, len(params['theta_list'])))\n",
    "conditions = {'t': 0} \n",
    "keywords = ['Entropy']\n",
    "result = get_data_by_conditions(df, conditions, keywords)\n",
    "entropy = convert_stringlist_to_float_list(result.values[0][0])\n",
    "print(entropy)\n",
    "plt.plot(list(range(len(entropy))), entropy, \"--o\", label=f'$$={params['theta_list'][0]:.2f}', color = colors1[0], ms=8)\n",
    "plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)\n",
    "plt.xlabel('Different Combinations of Partition of two subsystems')\n",
    "plt.ylabel('Entropy')\n",
    "U, t = params['u'], 0\n",
    "plt.title(f'Entanglement Scaling Laws for J = {t}, U={U}')\n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a026de-8fe0-4c92-9d43-ebab802b9132",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fbbc1d46-fb15-45a2-87e7-651aa2bc8130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 863.51 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.1\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "bd2396cb-89fb-4d58-a529-cd341f3d2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415b556-dda9-4316-be76-7291c2f0e405",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b28403-336a-4fea-b64b-04384e17081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fbe24-d824-45b3-9ca4-fb9562c1c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e28eb6-92ed-4e95-9e7c-d30a69952aa7",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7f1f7-a2a7-4535-b1f6-6fa180f01ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575c8d4-45cf-4e4a-bc39-440d3fc4be0e",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e87e59-8d40-4658-951d-a7fe57ad6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename1, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ffe55-b343-4a42-9802-d87a2a83cf32",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d74d1-7b0b-4f24-b75e-757a33f9190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060ddef-cd68-420f-bb3f-c1469a370f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab1a6b-888f-4299-9b75-befbb7dca84d",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf28cb-21cc-411b-bede-d582dc1fa2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f2472-4297-4975-948e-e0a78f4bdc0d",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a3c8f-3010-4434-a2c0-5b651c194924",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename1, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fcab3e-34b0-4b2b-8e16-c96e90f9c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4cbcd-8f2c-4d78-9412-77e941704a91",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e326b-d585-47b1-ac5c-c6e545444818",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa58bc8-d10b-4dfd-b511-036129f66799",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea986f-ca13-4365-a0c5-8d3789fb9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c858519-4da0-4eb6-abaa-f9745316c969",
   "metadata": {},
   "source": [
    "##### Correlation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228e4ea-9bbc-428b-93df-c7f5bbdfa564",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_index = (params['L'] - 1) // 2\n",
    "correlation_rate = hop_exp_val[middle_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7bcf7-3ee0-4b63-b5cf-3a3a8f27e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_rate = pd.DataFrame(correlation_rate)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "create_folders_and_store_data(params, filename, correlation_rate, key = 'correl_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057d1e1-c1e4-41b0-a285-a7a1761484f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f5b1efe7-fd37-4533-916c-04882b808a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 800.36 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.2\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "05c44ad2-3ba5-4a02-9ff9-a18f8a397b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0763ec-8488-4b55-a10a-3582778478dd",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef0af2-41ea-4314-9f07-06bc51c3a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bc344-24ce-4997-97f8-f4a8c3795da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df8027-f55e-4a95-a20d-82fd082f2422",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be249b9-520f-4a35-a10c-8484eed7ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52e0d2-f587-4a66-9838-4a1e587abe2c",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca44885-efa2-486d-a8f0-17ab876bf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154abbf-0302-413d-9c28-a2bbddfedfcd",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92057f-646b-4630-a4b0-8870fa1e7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9728ed-5116-47cc-95e7-9fb4a60f838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738bb96-ecd0-4444-9d1b-6ff57c610ae5",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f346c7b-b8e9-4f81-beb4-178df21aded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d7b01-5a16-403a-a680-b4c8e63877ad",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4bd93d-858b-4bfb-b092-0dcfc394a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfa3c3-ded7-45ce-b833-a6a301e85bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85641400-71b1-4350-9e5f-5dfd6dbe6b34",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ba8f9-8684-4ad4-a9d8-3bf060066442",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a54cd-ef9c-43a5-a98b-ad1df532cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a86b9-6e51-46e1-ae22-ba5419be287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6400934-96b5-45c4-9070-d83203a900d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8f2ba00-150a-41f8-a3df-2c2a0baa0a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 220.28 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.3\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e973de4d-1c47-43c2-9e13-a582a61d8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ddb137-857c-4d00-b760-501d2ba80178",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ddf0d-3e29-40fc-9328-76dd017873c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e8ccf-1cf7-448b-a27a-7bda027edfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4636446-887d-46e5-bf92-d2d3061804b8",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fe263-79a8-4d9e-81c5-e8e02344b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6c6fa-b0f7-4d8c-b51e-048a4c2db381",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f49d1a-8172-4c4d-8eb2-5e09e2fb2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a348611-16b8-4204-a641-68bf909eac61",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1dd3b-09b6-4fbe-bb43-cc7f10933c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22683846-308b-456f-a606-11ec41468a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa6d5d-b666-4b06-bf1a-deeda42ce04c",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60834e54-8927-4c58-a05e-15202e6aa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a50dc-ccf6-4fbe-b560-c079b5634b79",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a75166-ae38-4994-ba82-8340927ae791",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ce2aa-9e8c-4c21-93a6-e922817cedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4994f-60b4-4768-8151-448d2dbd4fcd",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d8c5a-28d6-4171-96a1-45f07d75be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a8134-1d29-45b6-a3f9-187bbd4351f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62bb79-d047-4a93-8c93-ac581f9712fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced1257-c4fd-4e99-a428-e3ce25780a3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06aef3e4-7e9e-4ff3-836a-b38278d5006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 779.63 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.4\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6935d52-2b3d-4d9b-ae97-07cfef1ae12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64cf02-da28-4fb6-aa48-4231f4081047",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36012d14-6f7d-4ffd-83b5-61d1f791f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6146da1-c570-4fd4-91ac-cb0cb76f7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31484e3-b265-45d4-8e91-cf63b829c1c7",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b8660-18a3-4514-88ec-d02a77641edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09d405-1919-4009-ad88-3d1841d917a3",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f6724-0f1f-48cd-8fe6-b51bf79e977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e48f7-1c71-4814-b274-dfee2e231850",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d249d-a993-4eb6-a772-10f57b58a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862dd203-0c85-4285-bd8d-691221bd218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d95ce-b8f7-4980-876e-13d620b65bf1",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246c6ee-2951-45d2-b2d0-9535d242303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0ddf5-d559-4a9a-898f-2c0ab9178035",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa59c0-223c-48f8-ac60-9801da938048",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c495f-c0c4-43f4-831d-949c6d73c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b46e15-3f09-499c-8d3b-21a0e2481892",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946b1e6-dc26-4c3b-b764-8827113aa34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b5d43-6858-4bac-8292-12f18d8c5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c554bffa-d487-451f-89c3-b93b31d8a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae700bef-3d65-401c-b73a-f9924694db79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82296a7d-d5f8-4d3b-af29-e894e0ac4e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 790.36 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.5\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38ab9729-07b5-421c-ad9f-ba7eb4713223",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5e88e-cd42-40b3-94bf-f8dce750fd96",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3936b6-f64c-44c3-9723-de6dbb76432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e73b1-d539-4a6b-8719-942c3f62b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9a0ab-f66f-4b8c-8a68-7fc84aca5c32",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f07f1-344e-43f2-bff9-d4832fc86afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561345c0-dfd0-44ef-bd8d-ef8c78830acf",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bf400-bd6d-47ae-ad06-6eb114fbaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb23e74-714a-44de-9274-23a62b3926fa",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088a7dc-05cf-40f1-8c3c-245aaa2b46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b1323-c7fa-4071-9ede-989e378c8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e1d55-3a15-4fc5-9ecd-766ea2384872",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d306f66-6c7b-4876-b580-25452e214e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2fc06-d8a6-4643-9cc8-66455dee63ef",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b3caa-9237-4ba9-b960-94eb3c6567b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff5d5e-d31a-4d47-ad39-c99c5044e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4759bc1-1a13-4040-b243-3a851d1a6587",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e311c-570d-487b-82d2-08d7f602bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef511f5-8dba-4520-bddd-4bb93fe7bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86a6d5-f40a-4929-9961-9cb61e26427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ea26b-552f-4171-b99f-a9a665be5bc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bdb4cd1-c731-4cab-9769-d6206a028958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 915.45 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.6\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79c03cd7-c31a-4a91-b1a5-33d378d11065",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cc4db-9f3a-4938-a592-1cc4ed9e6a3a",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830f13b-c943-4efe-acd9-bed280ebcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88aec3-4a66-43b8-9195-d6246c892e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cfcbe3-bfdd-4112-b900-df2c4c481d62",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b503df-675d-4d59-bf70-f1c3cca7173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b6bbf-a07c-46c4-935e-395cee1732c9",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e83122-91e4-4010-9b16-9a86bf99727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa4943-d22a-46fc-aa21-0a815f581464",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8e219-5fe1-44e1-88ff-c954f6b5054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aef4b6-3c3b-4b44-abaf-b8d4bd879e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be9846c-9888-4752-bdc7-79027ffd77ec",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9004b2e-1cee-4e44-96e6-26b571e04a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d22434-bdab-4f68-9b60-b723a630aa36",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c276fd-3ba9-4554-8acd-89c6a2a75f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74666b4f-001c-463c-814a-2343f4fbab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69803b1-99d4-4ce6-8e7f-ce7955d33903",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b90427-3ffb-43c7-beab-d866b9af675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b7351-ce6c-4d0a-9c30-6f7876757cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c9c42-71b6-4c66-a8f4-9d330ff7f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0e445-1c44-4baf-9f10-d754e672268e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aed2f58d-8ad8-4e6b-bd08-eef4ffec43ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1130.30 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.7\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a1e8fc7-ea5d-4902-bfcf-9fede327edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893334a-2df0-41a4-a847-ee5875080835",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895b671-2db5-41ff-9f1c-9703684b7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8301c-fe52-43f8-ac29-85f99a8f4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abc494-451c-49e4-a3c3-c2b4003ce0ac",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00ccea-e398-483b-b82e-e5a337724e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457cdaaa-5fcc-4fe9-be6c-f2283d913319",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1d25e-7bb8-42e9-a6e5-4b5a47853370",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a61809-f7af-4c40-a5f1-86dae6352f9c",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd454d4-0ae0-4d15-b7e6-ec78ac825786",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be18e9-21c1-4b06-9ac5-7c20f08f6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce973a9e-cbb1-4a5f-81be-35101961d0bd",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635beafe-0610-4acb-be1d-d5972d780fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980b5a3-e794-4257-8a5e-b2cfede6a996",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695a8cb-fa8a-426f-85b9-2a2a73068e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cffe4-cad1-45d0-a0b5-70a6af7f2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f1bf8-06c4-43d8-9e85-a7f006c18719",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb2280-0d11-4879-8165-baeafef1fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4202a8-ea24-4bdc-99f9-d8cb6bf395c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5184b76-85df-4f8c-826e-a18630956d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1120e-6dd8-4380-af7e-55ee8e8687a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14b671fc-d658-4bf9-9b75-924c0329bc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 895.10 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.8\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd16794b-fc0f-4561-b655-108416e7dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392b38a-2317-4b52-932a-c8fa80fb6631",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b490f1-4e66-4f48-9170-3c03d85c637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e516bd0-6f46-4906-bdba-c7b3625a8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901d5a5-bb64-4ba4-ad32-065b0f32c4dd",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27cf4f-e27a-4916-a443-4cb60698e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2cc0d-85ab-4a4a-9651-2eeb66f5c19a",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb21e56-b40d-41cd-bd26-5e1985bfd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a4b6a-91e6-41f4-9a19-9ca8acc48e6f",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacacfa8-25ad-4a66-ae7a-04aa081255f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478835f-916e-4e28-9143-636e82d397b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f518d4-a694-44a1-8e97-43f20b1efdc5",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d1b34-fe95-460e-8bf9-e2cd9c716fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5bcdd-506a-4541-89c4-c48c6397944e",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c30c45-11d4-4d3a-a911-beec5c5940eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adeaa4b-0d38-4ec2-a198-2b525030f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047f11e-ef66-4e6c-81b2-a1ba8ddf727e",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65600f2-6253-4026-9a3c-44f2f9a13672",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f031d-e06d-4934-95a6-eb6a3ffb7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315e292-ea07-4356-8878-585eebbefb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a1a0b-d5d6-4850-87fc-43b490961d5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "def54c55-3a50-44af-b4d9-e4592d831138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 991.20 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 0.9\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0287e058-2a03-4d9a-96fb-35f482d31e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3d067-cb91-485d-aaaf-e628e8ff09ea",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b6f80-dce6-4536-b1df-63bc2683548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48929afc-8dd1-40ac-a8c5-435cdea49cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb63787-2c8f-4dfc-9f41-4d3781a35207",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567877a6-3395-48b2-9db7-a99dabaec59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdfd0a5-320f-4d64-9f2d-fb08065239d4",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf427d6d-c64d-4f67-a577-bf769fbe8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0955bbee-2b30-46c2-80b4-3d065d3c9ca4",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66f2e7-9fb7-4b4e-aee9-5a12ddba43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a6f20-f5cf-4af0-80d7-6b1fe0684d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443ce51-d1fd-4fb9-a676-bed77b206bec",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37389791-8f85-45ea-9630-63a3efc22747",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c81d2-ad29-4461-a59b-f024a14143ec",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa979a-f37f-4670-bd5b-59fdd662b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98278f-0640-4c0a-9343-fdbdb14790cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8287216-b26b-4684-845f-1a2e10a60fc3",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c6117-5201-49cb-9803-fb39f9ffad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2767d-154f-4617-a8b0-24c6cc6ac0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca514918-3252-4431-9f4c-60457ac6ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065e2b3-5ac5-48ef-b5ae-a5600a9cb429",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "778e3828-e1f4-4cb5-b6e1-df07061a3f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1092.06 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d4c419ff-5df2-48bd-bf78-4b52259447a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902e024-54dc-4d14-9616-7ee62e4ca324",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8176e-b2da-4f00-86fa-90b7b1e561fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cef1aa-ba07-4835-894d-91e691eaa1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492b109-e57d-4752-901c-b8d14bf5d3e4",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eda10e-a6fd-48d1-b370-3ccce8445501",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb43e7-e940-41f0-9909-8f456c45a1cf",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c704284-57c7-499c-8b7a-66058e246395",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "append_data_to_hdf5(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2800d-e9d7-492a-89e1-261c8b61aef2",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5af5f9-35cd-4c31-81aa-1e6a23f7365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203ed0c-7f68-4f72-8020-5f82cf138d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76042f-379b-4065-97db-8fcae397b219",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53fdd5-65f2-4b93-a530-da43a4eef20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e0590-42dd-434e-853d-635a05697c72",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1e1f5-869c-423d-8c90-1dd441593c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04dbe6-9eb0-4065-8317-7c7039630686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dde5a-e3f4-4219-8c48-d83cd4dee277",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc1c9f-235b-4ce9-a7f3-b0904ea9add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db256870-ba39-48fe-a01d-2af4e6e473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f16a8b-b813-4e65-864c-e1126ac67591",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450d4db-2687-4e3f-b971-767f445ad30b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0864a0d3-2aad-4711-b688-8664a5953e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 834.51 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1.1\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ad6ac8b-a3bf-4af4-bee5-af985d26d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c636c1f-1129-4605-96ef-9043858735fa",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cd7e01b-ed79-44e4-a860-15e6e37878e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "150cf460-5046-4b67-a5d3-2dde0f2d2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09796077348093837\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0985f-9470-4494-8031-291b625a3a0f",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf9f8ed4-df5e-414e-a572-eb532df1841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639d006-80f4-4380-9721-82d3124b1fbd",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2fd6791-a95c-4d02-905f-3a6db0520977",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename1, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170f224-eabf-44a9-8059-a771bba7aa7e",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78534b25-1b7d-4b3a-b850-a7b4cde0f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f043830-9f7b-4fcb-b313-98579b2bbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b60951-dfed-47f8-a133-d6e1b7867ee0",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5564fe4-738a-4a93-ad2f-5705f171dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efde776-3af8-47de-8f9e-d490ac6ed9e6",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a091bed-c3e7-476b-aa7f-25e504201830",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ade4f928-fcec-47fe-ba71-cf963660a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a18293-cceb-462d-b9b4-ce658db45f2e",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd40a1ec-dea1-43f5-a785-b9156ca40618",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a915d152-05e5-4cb2-908f-50de59b93b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5946162603366946+5.70775432678586e-18j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2aed4dd-1418-4e6e-ba24-e14ca276e45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_1e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_1e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07748ba-c2a2-4047-bab5-30ca66bec080",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9fcb798-66d3-4c7a-a8a4-598236fce087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 681.43 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1.2\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c5e526d-96aa-4d6a-86d1-daaefec9089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7162c8-82a6-4c0b-9524-8ba839082852",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc42e1eb-e159-42c0-914d-4885aab075ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d144a6c-1367-4304-85cf-377fae08ac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.126729439472895\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5bc24e-98a9-4381-af17-f4b4ef605cff",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f56e258d-9cc5-40f7-9c31-d3616cd58296",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b26c08-29ae-4fb7-b606-103ed15412c2",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bd8822a-fd22-4c6c-b66b-2de92815a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5aedc1-c08a-41e2-9447-035ba94b6f6c",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "304d5dbd-d605-433c-be6f-edbd5f5e9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e3f6385-289f-47f3-9cce-621dfe2d17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc7d3c-0f7b-41df-8f2f-c44eeb48f73a",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7afaa8a7-2b45-4a89-8eaa-6a796c63e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a11ce3-dfe1-4dc0-b064-7aeb1549cb28",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81c9959d-d064-43ae-b9fb-21f92783a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0938d3a-1b9c-46aa-a4f5-6090e60c3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487efde0-4e7f-47b8-a4db-a49f48fb8751",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9eb435c6-c8ac-452e-bcee-d83d28eaa5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee264e8e-e261-4d71-8d14-feb0d671384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5860815647207849-1.1528847906497122e-21j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b41cfa0b-39fa-49b7-a7f4-a2490212e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_2e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_2e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6911b-8624-48ad-9636-3059d040f72e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de292ccd-10da-4435-b9fb-b10385d82eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 715.77 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "\n",
    "params['u'] = 1.3\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c38ac61e-3063-4628-a87f-c56e6e1f334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccdc37a-7969-40b2-be98-111949d72836",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f608320-d1bf-4cd6-ae97-2ea3d906c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fcf84222-06d8-4922-8f86-9b215e7c54e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15953834695005428\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd86c8-12dd-4a95-ab8b-91ac649bd34d",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64014bdc-725f-42a6-9e0d-225f82df744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e05bd-6b30-4cf2-8360-dbca224b9f71",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32515660-0311-4b4b-8ab3-0e0604244f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ac005b-82be-40fb-83a9-d444e81240db",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e42aee4f-88d1-475b-80a7-76705bc52939",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e450e69-6a29-4b67-9768-be4ac542af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cf100-147a-4e38-9f80-834563306dda",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ade0ea7-93f4-465e-8b74-3de482b5cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36d1a4-20f1-41a8-8d90-a998799d0da6",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "769cb477-41c3-49f5-957b-12dd70d4222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f191d-22aa-44ac-abc0-a788665889f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3ce9c-c784-4076-b653-151d75961ad2",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a462565a-da8f-49e6-93dc-9d65278c8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21798326-28e9-4a5e-a2c7-fcc2bd548106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5779267524321549-1.7144064649330196e-17j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77f16898-57e5-46d8-9816-9a7c6824ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_3e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_3e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71562ede-ab8b-464c-ba4e-3fc52119dc31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "62490d6e-20ad-4ee8-9ea8-31b7a28637b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 685.73 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1.4\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f4508cb-e68f-4aa2-a0a4-43c89923be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab02925-c50f-4279-bb9a-f5462054115f",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "96bf3c79-2a74-4ea9-9fe3-578bc0bd0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40b573a2-02da-40ab-8031-64fdc04efb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19648481780403435\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48dfbec-2d82-4423-a548-82ba5caec8c3",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d095ec11-7732-4a25-85bb-f42b18e25ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454be913-02cd-41a6-9885-430c1ffbee35",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "997ffdb4-97e3-4413-ae36-6abd40e67ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b51ea-1409-45e2-bf5b-753f26d2650f",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d8465b8-3a69-45ab-ab01-eb19404ee457",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b93eba6-de43-4037-b11c-f43d38c06e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8adac-bf00-4c36-befb-e9d83d699cdc",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa1637e5-5366-4e65-b176-fef3dbbde84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0944081d-46d3-4ebd-bffc-2a0ee94d9891",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86120f75-e181-4825-9720-f9277d05eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc309fb-42f0-4dc9-a0db-aee0755fb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc21aaf-9eda-4e25-b001-e6c34969c324",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "261494b7-46da-4177-bb1f-ec7bccefbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "691bd180-2409-4d3d-ad67-66f88728f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5700942497795861-4.7493082991761236e-20j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eca95802-e46e-4848-a80a-4ea7b916d4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_4e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_4e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c55cb-f2c5-424d-a1e0-9a79034e1f3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e109850-fed0-4179-95a2-eb31370a7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 726.77 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1.5\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cfd03e3d-8556-4a86-b05c-fe835598b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7b6d5-153b-4bb7-ba29-feafc4c6da09",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06f2726a-bd0f-4cf8-9f73-36ebbe64f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f6b3ddbc-a1a5-4681-a110-bb7c08c5d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23767422292100363\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec88307-2e73-4f1b-af06-bfafa8f6981d",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd18484c-a06d-4495-9a41-4c447da42ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e86335-c496-49cf-ad95-d1f0e3afe18e",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb7566e7-01c2-4821-942e-6ade657778a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff058be-0d54-4619-aa99-93d822ef4f9e",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51ff98f7-8624-456e-bacb-c5f7c184f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10e6e121-48de-492b-8da8-ff61777082b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab5526-bf2c-45bb-b228-63c6705e88a1",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "97ed6f27-c6b8-4f88-8475-2b60f28e4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7e88-fad7-488f-8c3a-c936a6774bae",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "29f86276-f9d0-4e59-94a4-cc30307dbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a5881f7-53b6-4ff5-9869-bc1b666c4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ce924-56ba-43d2-b54a-6ee2c7b92a76",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d3a2a12-91de-40dc-a87b-b10e5285ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a01eec54-b953-4ae2-9433-696ce57e285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5625410888910505-1.3460986742849055e-17j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2d7a11ae-b834-454b-9ac4-b6f126da986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_5e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_5e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee0807-56ed-456b-99a6-75fa24c228a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "531119f8-071f-438f-9028-e1407644b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 588.03 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "\n",
    "params['u'] = 1.6\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d49abe8-8e17-4a05-acb9-6dbafd8e49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917383b-2779-4967-b680-5e933f1dfc3a",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "32b8241b-bd51-4544-a8b1-6869b8ae6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "108332ea-8a98-4d6d-9047-63f6777167bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28322013029832727\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921b1a3-4673-4652-9d98-8f4636eabbcf",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f3a2924-a0d6-41fd-97cb-c9e07c580058",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f489f48-759e-4b47-8545-38c32e485fa4",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cd407141-3d01-439d-bfea-95ef4c9d9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404c458-3016-4fb0-9648-cff8881ffb9e",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b3f91ec7-4326-4369-85d8-51b83f0aecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7b40437-dcb9-41aa-b93e-411acf232cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971674b7-ee16-43d9-a5e6-088af109a9e2",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0538529c-e418-4ca2-a438-af5bb04983f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dafa84-26e6-4c41-a8ad-12d6eb29198b",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9977be5b-8d78-417b-a151-45971bf7292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a7fb8a54-f383-4b4a-a253-ddb392e4c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1cbe7-bd0e-49f0-bab8-7bb007c386c4",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d7117fe-ce4c-468c-a4cb-165ce5146856",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8df120b9-9fd8-4cc3-89a5-57589579fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5552319382724015-4.920592101425538e-19j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39caa17a-1779-4d91-969a-9ec44fb1cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_6e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_6e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6168f8-2221-4048-9887-f5caffad7061",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "04065528-10a7-4f63-9dc6-6e35a0c4a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 594.13 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "\n",
    "params['u'] = 1.7\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0d1dfc65-3dc1-4540-88b1-2e612c146efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9566e21-3281-4051-afe7-a6f65c1b76bc",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "60eddf03-9193-4716-ab54-eacefe1555be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc6c8007-f685-4e3e-a479-72e3c1522fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3332433399496952\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c37ae-3689-4d25-91a2-a515ea76fc2b",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2056e20b-409e-4456-ab00-9c66a51237ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f78c8-2852-48be-aedd-adcdfc9bfb4d",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6cf124e5-13e5-43db-b3e0-903a109d8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465d095-0c2c-4af3-8947-caa3e7c5eb56",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "863c5d84-b4b8-443b-82e7-be13917987ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "95dbdf5a-b0e6-4bd3-9de7-6cd32c53be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05eb612-a56b-4aad-8f3f-9c94c149f80e",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a9b960bc-fcea-43b5-bcf8-69eddb312fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd102e3-f4ef-4982-9826-706aea1e53f9",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c921ad1d-aee5-41b9-8198-03ed10a74da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5daf0e8c-cd35-42e7-8376-3c1d708b8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8893b0-f91d-4b5f-a29e-d8841c429f11",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d9282cc-d3bc-4c95-912d-63e4b5962818",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9cc8abd4-ad40-4b14-afd3-804da461810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5481397683533945+3.2793257087840163e-19j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b0d898a-6948-453d-9ad4-e3ef61a1c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_7e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_7e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66763d61-29fb-4998-81c2-6b7dae8c7312",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b34ffa63-4f81-4b56-bc75-0a22b2ae5454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 537.55 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1.8\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "086be243-668f-4409-9681-2b985ed913f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042ad59-6265-4f2a-b769-0395fc6054d8",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "782d5aba-e945-4ddf-8ee8-3a79f7e7b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c4e00834-7570-47d3-858e-d19e6719a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3878714608166634\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0b9be-8867-4619-a7d0-79a6bb22eaae",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff09213a-df16-4ecf-ad09-bc008a6909bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370afddc-2a49-4fb7-9d2b-213df4bcc5c0",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c49b797-6f43-489f-a701-5d16730e7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9eb15b-1913-477f-937e-f108817c8f66",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3be09d4b-da6c-44ed-9ee3-56f1d254018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cafa329e-9950-40dd-8b81-0ae9ceebc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd50dcc-8f53-46cd-a8ed-b1a2b81d8d3c",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f28d61ef-671c-48c5-877e-59fa18ce04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd325f-b489-4e50-b664-c09f8ed08fc2",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bdf74028-414d-41e6-82f2-086dae0b370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e9e01-109a-4aab-b5db-4b4b862cd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952feee6-0522-4261-a30d-66f588927def",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "033ea303-9cbb-43ca-885d-dff839166f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6349f66b-9a8b-4729-9f7d-a7577b953c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5412424548958277+2.0023962042151742e-17j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7b330a46-5f7c-44be-8122-b38f8769b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_8e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_8e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e599f4-aa75-4499-87ff-0895d1e66cca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 1.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3c670c46-ea3d-400c-beab-6ddb49cdcae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 476.51 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 1.9\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cc9f6cca-6add-4001-b14c-7facdf40cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043dd88-3158-4a13-b294-b717ad02db0a",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3370c1f5-342b-44ea-9c92-33bfec2c9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d66c50b1-9ad0-465c-b8f0-a1c7b4b5c68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4472382152563802\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d088a-c269-45db-88c1-b3c5cde7e62c",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4ea9f9eb-1225-4280-a2ea-390a60f32e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dbd299-7a43-414f-8bf6-7084b6d7f11a",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "910115ae-f5a4-40b2-8476-27d37ae436ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d77ec7-7699-4e05-95e0-73288f795c8d",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cfb78a91-53bb-4f4c-837d-253ef2a667e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "93fa9902-b198-4661-8a31-556b2539d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c3861-d53b-48b1-a68a-df29723890f8",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "75ad3fab-e54a-4c04-b183-eb96961376f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4c137-63d4-4339-afa8-a768f1e5bc51",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "55b0665c-b989-4c57-8192-100875d6f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29add2-f895-420d-bb29-045eb75cb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ab304-1b40-4919-85dc-88f0f80f5f52",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "25992687-e1b3-4645-931a-1f0a0fc8891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c6d23b3b-c75f-410e-8cad-f7edffcd5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.534521901889944-1.918836298302944e-18j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "28c9ad6d-9d46-4b7f-9222-d80a131f90ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U1_9e0_t1_0e0\n",
      "/std_deviation_numberOp_U1_9e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1087f15-0f41-436f-8833-4fb553e2a381",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### $U = 2.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61fff8c6-6329-4d59-ab8c-040827962a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 546.78 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#########################################\n",
    "\n",
    "params['u'] = 2\n",
    "driver.initialize_system(n_sites=params['L'], vacuum=Q(0), target=Q(params['N_BOSON']), hamil_init=False)\n",
    "driver.ghamil = driver.get_custom_hamiltonian(site_basis, site_ops)\n",
    "b = driver.expr_builder()\n",
    "\n",
    "# b.add_term(\"ADCB\", np.array([[i, i+1, i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"AD\", np.array([[i, i+1] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"CB\", np.array([[i+1, i] for i in range(params['L']-1)]).flatten(), -params['t'])\n",
    "b.add_term(\"N\", np.array(np.arange(params['L'])), -(params['mu'] + params['u'] / 2))\n",
    "b.add_term(\"NN\", np.repeat(np.arange(params['L']), 2), params['u'] / 2)\n",
    "\n",
    "mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "mps = driver.get_random_mps(tag=\"KET\", bond_dim=50, nroots=2)\n",
    "energy = driver.dmrg(mpo, mps, n_sweeps=10, bond_dims=[50] * 4 + [100] * 4 + [150] * 4,\n",
    "    noises=[1e-4] * 4 + [1e-5] * 4 + [0], thrds=[1e-10] * 8, dav_max_iter=30, iprint=0)\n",
    "\n",
    "#########################################\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d44b3a46-3ddb-4d97-ba20-f88b4281e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kets = [driver.split_mps(mps, ir, tag=\"KET-%d\" % ir) for ir in range(mps.nroots)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36d575-47f9-4bbc-b968-0451d07dcd9b",
   "metadata": {},
   "source": [
    "##### First Excitation Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2688513d-9afd-4680-9901-83151ae861d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gndenergy = pd.DataFrame({'gndenergy':[np.power(np.abs(energy[1]-energy[0]),2)]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "## Complete path\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, gndstate_energy = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, gndenergy, filename1, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e079c21c-ddfd-467e-a0d9-3ea5a86ffb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5114828185251709\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "gndenergy = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(gndenergy[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e8e82-724f-4bf5-a509-d4d28e74eaf7",
   "metadata": {},
   "source": [
    "##### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "30c8e5d8-3604-44a8-9d03-bafa75901800",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy1 = driver.get_bipartite_entanglement(kets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e438b38-e944-42c7-8be9-d2a17b2cbb68",
   "metadata": {},
   "source": [
    "###### HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9e5fd169-4083-4276-b371-088edc01f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = pd.DataFrame(entropy1)\n",
    "filename = generate_file_name_hdf5(params, entropy = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, entropy = True)\n",
    "create_folders_and_store_data(params, entropy, filename, key = 'entropy', entropy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6f90c-c989-455d-88bb-b28763035d96",
   "metadata": {},
   "source": [
    "##### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3e7e029d-0ace-45c6-ae50-31e3a3684d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_exp_val = np.zeros((params['L'], params['L']), dtype=complex)\n",
    "for i in range(params['L']):\n",
    "    for j in range(i, params['L']):\n",
    "        b = driver.expr_builder()\n",
    "        b.add_term(\"CD\", np.array([i, j]), 1)  # Hopping operator between i and j            \n",
    "        hop_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "        hop_exp_val[i, j] = driver.expectation(kets[0], hop_mpo, kets[0])\n",
    "        hop_exp_val[j, i] = np.conjugate(hop_exp_val[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "74854106-a316-4650-9f0c-3840aefc16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_matrix = pd.DataFrame(hop_exp_val)\n",
    "filename = generate_file_name_hdf5(params, Correlation = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, Correlation = True)\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)\n",
    "\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, correl_matrix, filename1, key = 'correl_matrix', Correlation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96f0dc-f4b8-48c6-ae6e-9e0c93b1aca6",
   "metadata": {},
   "source": [
    "##### NumberOperator and Its Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ac6773fe-30c3-4c89-a9e3-00bc3a078fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val, std_nOp = 0, 0\n",
    "_exp_nop = []\n",
    "for i in range(params['L']):\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"N\", np.array([i]), 1)\n",
    "## Calculate <N>   \n",
    "    nOp_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    impo = driver.get_identity_mpo()\n",
    "\n",
    "    nOp_exp = driver.expectation(kets[0], nOp_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0])\n",
    "    _exp_nop.append(nOp_exp)\n",
    "## Calculate <N^2>\n",
    "    b = driver.expr_builder()\n",
    "    b.add_term(\"NN\", np.repeat([i], 2), 1)\n",
    "    \n",
    "    NN_mpo = driver.get_mpo(b.finalize(adjust_order=True, fermionic_ops=\"\"), algo_type=MPOAlgorithmTypes.FastBipartite)\n",
    "    NN_exp = driver.expectation(kets[0], NN_mpo, kets[0]) / driver.expectation(kets[0], impo, kets[0]) \n",
    "## Calculate Standard Deviation\n",
    "    std_val+=np.sqrt(NN_exp - (nOp_exp*nOp_exp))        \n",
    "std_nOp = (std_val/params['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60aadd2-29c1-4390-8998-e8a605641844",
   "metadata": {},
   "source": [
    "###### Expectation value of Number Operator on each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "34f8e85e-7caa-4741-93e9-9b5390e43bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_nop = pd.DataFrame(_exp_nop)\n",
    "filename = generate_file_name_hdf5(params, expnop = True)\n",
    "## Complete path of the location of the file\n",
    "filename1 = generating_complete_path_hdf5(filename, expnop = True)\n",
    "key = generate_unique_key(params, exp_nOp = True)\n",
    "append_data_to_hdf5(params, density_nop, filename, key = key, expnop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8034846-b7e7-4116-b928-ce3e180a949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = generate_unique_key(params, exp_nOp = True)\n",
    "# density_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "# print(density_nop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e80d12-4ed5-4bba-98e4-0e0b379defd4",
   "metadata": {},
   "source": [
    "###### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b1eb22b-c4bf-4f8f-a8c2-c58d22d1d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_deviation_numberOp = pd.DataFrame({'std_nOp':[std_nOp]})\n",
    "filename = generate_file_name_hdf5(params)\n",
    "filename1 = generating_complete_path_hdf5(filename)\n",
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "\n",
    "## Use the code below to append data to an existing file/folder directory\n",
    "append_data_to_hdf5(params, std_deviation_numberOp, filename1, key = key)\n",
    "\n",
    "####### Use this only for the first time when taking data for a theta #######\n",
    "## Use this code to write data to a new file irrespective of the presence of subholder based on 'L'.\n",
    "# create_folders_and_store_data(params, std_deviation_numberOp, filename, key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9e449520-5971-400f-8256-ff011c237234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5279631565100674+1.7169286087317354e-18j)\n"
     ]
    }
   ],
   "source": [
    "key = generate_unique_key(params, std_deviation_numberOp = True)\n",
    "std_nop = load_matrix_from_hdf5(filename1, key = key)\n",
    "print(std_nop[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "57c7146c-926d-47a0-80a0-5cbdd47fa1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in HDF5 file:\n",
      "/gndenergy_U2_0e0_t1_0e0\n",
      "/std_deviation_numberOp_U2_0e0_t1_0e0\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(filename1, 'r') as hdf:\n",
    "    # List all keys in the file\n",
    "    keys = hdf.keys()\n",
    "    print(\"Keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
